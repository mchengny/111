{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Define the node of Kd tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Kd_node():\n",
    "    \n",
    "    \n",
    "    # Define the node of Kd tree\n",
    "    def __init__(self, data=None, label=None, split=None, left=None, right=None):\n",
    "        \"\"\"\n",
    "        Initialize the parameters of node\n",
    "        \n",
    "        Arguments:\n",
    "        data -- feature vector of the input instance\n",
    "        label -- label of the input instance\n",
    "        split -- the spliting dimension\n",
    "        left -- left child node \n",
    "        right -- right child node\n",
    "        \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.split = split\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Define KNN Classifier\n",
    "- Note: must transfer X_train to ndarray，and encode Y_train into np.float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNeighborsClassifier():\n",
    "    \n",
    "    \n",
    "    def __init__(self, k_neighbors=3):\n",
    "        # Define the num of k-nearest neighbors\n",
    "        self.k_neighbors = k_neighbors\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def generate_KdTree(self, data_list, label_list):\n",
    "        \"\"\"\n",
    "        Generate the Kd tree by recursion method\n",
    "        \n",
    "        Arguments:\n",
    "        data_list -- a series of data points in feature space\n",
    "        label_list -- the corresponding labels of feature vectors\n",
    "        \n",
    "        Return:\n",
    "        root -- the root of generated Kd tree\n",
    "        \n",
    "        \"\"\"\n",
    "        # Recursion: Base line, split end when there is no point in subspcae\n",
    "        if len(data_list) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Extract length and num of dimension of training data \n",
    "        num_data = data_list.shape[0]       \n",
    "        dim_data = data_list.shape[1] \n",
    "        \n",
    "        # Initialize max variance and splitting dimension\n",
    "        max_var = 0\n",
    "        split = 0\n",
    "        # Find the split dimension which has the max variance\n",
    "        for i in range(dim_data):\n",
    "            col_i = data_list[:, i]\n",
    "            var = np.var(col_i)\n",
    "            if var > max_var:\n",
    "                max_var = var\n",
    "                split = i      \n",
    "                \n",
    "        # Sort data_list and label_list along the splitted dimension\n",
    "        indexs = np.argsort([v[i] for v in data_list])\n",
    "        data_list = data_list[indexs]\n",
    "        label_list = label_list[indexs]\n",
    "        \n",
    "        # Choose the median of list as splitting point\n",
    "        data = data_list[int(num_data/2)]\n",
    "        label = label_list[int(num_data/2)]\n",
    "        # Generate current Kd node\n",
    "        root = Kd_node(data, label, split)\n",
    "        \n",
    "        # Recursion Call: generate left and right child node of current node\n",
    "        root.left = self.generate_KdTree(\n",
    "            data_list[0:int(num_data/2)], label_list[0:int(num_data/2)])\n",
    "        root.right = self.generate_KdTree(\n",
    "            data_list[int(num_data/2)+1 : num_data], label_list[int(num_data/2)+1 : num_data])\n",
    "        \n",
    "        # Return the root of this Kd tree\n",
    "        return root\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Fit training data\n",
    "        \n",
    "        Arguments:\n",
    "        X_train -- input training dataset,  shape = [n_samples, n_features]\n",
    "        Y_train -- labels of training data, shape = [n_samples]\n",
    " \n",
    "        \"\"\"\n",
    "        # Generate Kd tree and get the root of it\n",
    "        self.root = self.generate_KdTree(data_list=X_train, label_list=Y_train)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def predict(self, query):\n",
    "        \"\"\"\n",
    "        predict the corresponding label of query point\n",
    "        \n",
    "        Argument:\n",
    "         query -- data point waiting for classifying\n",
    "        \n",
    "        Return:\n",
    "        label -- the result of prediction\n",
    "        \n",
    "        \"\"\"\n",
    "        knn = self.find_knn(query)\n",
    "        label = self.vote(knn)\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    \n",
    "    def find_knn(self, query):\n",
    "        \"\"\"\n",
    "        Find the k-nearest node in Kd tree\n",
    "        \n",
    "        Argument:\n",
    "        query: data point waiting for classifying\n",
    "        \n",
    "        Return:\n",
    "        knn -- the list of nodes which are k-nearest for query point\n",
    "        \n",
    "        \"\"\"\n",
    "        # Initialize a list for storing searching path\n",
    "        node_list = []\n",
    "        # initialize a list for storing k-nearest nodes\n",
    "        knn = []\n",
    "        # set root of Kd tree as current node\n",
    "        temp_root = self.root\n",
    "        \n",
    "        # Use binary search to create the searching path \n",
    "        while temp_root:\n",
    "            # add this point into searching path\n",
    "            node_list.append(temp_root)\n",
    "            # Judge and update the list fo k-nearest nodes\n",
    "            if len(knn) < self.k_neighbors:\n",
    "                knn.append(temp_root)\n",
    "            else:\n",
    "                knn = self.update_knn_list(knn, temp_root, query)\n",
    "            # Decide the next searching direction by splitted  dimension\n",
    "            split_dim = temp_root.split\n",
    "            if query[split_dim] < temp_root.data[split_dim]:\n",
    "                temp_root = temp_root.left\n",
    "            else:\n",
    "                temp_root = temp_root.right\n",
    "      \n",
    "        # Back track along the searched path\n",
    "        while node_list:\n",
    "            # Simulate stack by list: last-in and first-out\n",
    "            last_node = node_list.pop()\n",
    "            last_split = last_node.split\n",
    "            # Whether need to go into the other subspace  of parent node\n",
    "            temp_max_dist = self.max_dist(knn, query)\n",
    "            if abs(query[last_split] - last_node.data[last_split]) < temp_max_dist:\n",
    "                # Set the direction of subspace for searching\n",
    "                if query[last_split] <= last_node.data[last_split]:\n",
    "                    temp_root = last_node.right\n",
    "                else:\n",
    "                    temp_root = last_node.left \n",
    "                # Whether subspace exists\n",
    "                if temp_root:\n",
    "                    node_list.append(temp_root)\n",
    "                    # Update the knn list\n",
    "                    if len(knn) < self.k_neighbors:\n",
    "                        knn.append(temp_root)\n",
    "                    else:\n",
    "                        knn = self.update_knn_list(knn, temp_root, query)\n",
    "                        \n",
    "        return knn\n",
    "    \n",
    "    \n",
    "    def vote(self, knn):\n",
    "        \"\"\"\n",
    "        Vote that choose the label which appear most frequently in k-nearest nodes\n",
    "        \n",
    "        Argument:\n",
    "        knn_list --  node list of k-nearest neighbors\n",
    "        \n",
    "        Return:\n",
    "        label -- the label which appear most frequently in knn list\n",
    "        \n",
    "        \"\"\"\n",
    "        # Set a dict and its key represnts the label and value represents the frequency of appearance\n",
    "        d = {}\n",
    "        # Count frequency of each label\n",
    "        for node in knn:\n",
    "            if node.label in d:\n",
    "                d[node.label] += 1\n",
    "            else:\n",
    "                d[node.label] = 1\n",
    "        # Get the label which appear most frequently in knn list   \n",
    "        label = max(d, key=d.get)\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    \n",
    "    def update_knn_list(self, knn_list, temp_node, query):\n",
    "        \"\"\"\n",
    "        Judge and update k-nearest neighbors\n",
    "        \n",
    "        Arguments:\n",
    "        knn_list -- current node list of k-nearest neighbors\n",
    "        temp_node -- temporary node \n",
    "        query -- data point waiting for classifying\n",
    "        \n",
    "        Return:\n",
    "        knn -- the list of nodes which are k-nearest for query point\n",
    "        \n",
    "        \"\"\"\n",
    "        # Get the distance between temp_node and query\n",
    "        current_dist = self.compute_dist(temp_node.data, query)\n",
    "        # Get k-neares nodes\n",
    "        knn = knn_list\n",
    "        # set max distance as zero\n",
    "        temp_max_dist = 0\n",
    "        \n",
    "        # Calculate the max distance in current knn nodes\n",
    "        for i in range(len(knn_list)):\n",
    "            feature_vector = knn_list[i].data\n",
    "            dist = self.compute_dist(feature_vector, query)\n",
    "            if dist > temp_max_dist:\n",
    "                temp_max_dist = dist\n",
    "                index_del = i\n",
    "                \n",
    "        # Whether need to replace a node in previous knn list \n",
    "        if current_dist < temp_max_dist:\n",
    "            del knn[index_del]\n",
    "            knn_list.append(temp_node)\n",
    "            \n",
    "        # Return the list of knn nodes after updating\n",
    "        return knn \n",
    "    \n",
    "    def compute_dist(self, v1, v2):\n",
    "        \"\"\"\n",
    "        Calculate the Euclidean distance between vector_1 and vector_2\n",
    "        \n",
    "        Arguments:\n",
    "        v1 -- the 1st input vector \n",
    "        v2 -- the 2nd input vector\n",
    "        \n",
    "        Return:\n",
    "        Euclidean distance between v1 and v2\n",
    "        \n",
    "        \"\"\"\n",
    "        return np.linalg.norm(v1-v2)\n",
    "    \n",
    "    \n",
    "    def max_dist(self, knn_list, query):\n",
    "        \"\"\"\n",
    "        Calculate the max distance between knn list and query point\n",
    "        \n",
    "        Arguments:\n",
    "        knn_list -- current node list of k-nearest neighbors\n",
    "        query -- data point waiting for classifying\n",
    "        \n",
    "        Return:\n",
    "        max_value -- the max distance \n",
    "        \n",
    "        \"\"\"\n",
    "        max_value = 0\n",
    "        for i in range(len(knn_list)):\n",
    "            dist = self.compute_dist(knn_list[i].data, query)\n",
    "            if dist > max_value:\n",
    "                max_value = dist\n",
    "                \n",
    "        return max_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate artificial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[3,3], [4,3], [1,2.5], [0.5,0.5], [2,2], [1,5], [2.5,1.5], [3.5,2.5], [1.5,3], [1.5,2],\n",
    "              [1.0,4.5],[2,4.5], [3,4.5],[0.7,3.7], [3,2]])\n",
    "y = np.array([1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1,-1, -1 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(3)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizing\n",
    "- 蓝色点为待查询点，其最邻近的三个值有两个'+1'，一个'-1'，因此分类结果输出'+1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d3f4df4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_1 = plt.scatter(x[:,0], x[:,1], c=y)\n",
    "query = np.array([3.25, 2.5])\n",
    "fig_1 = plt.scatter(query[0], query[1], c='blue')\n",
    "print('Prediction: ', model.predict(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
