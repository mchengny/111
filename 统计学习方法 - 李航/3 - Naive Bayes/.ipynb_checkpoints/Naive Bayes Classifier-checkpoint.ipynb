{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes():\n",
    "    \n",
    "    def __inint__(self):\n",
    "        \"\"\"\n",
    "        Initialize the model\n",
    "        \n",
    "        Arguments:\n",
    "        prior_prob -- prior probabilities of each Y=ck\n",
    "        x_variety -- a list for the potential types of each dimension in feature space\n",
    "        con_probs -- conditional probabilities of P(X=x|Y=ck)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.prior_prob = None\n",
    "        self.x_variety = None\n",
    "        self.con_probs = None\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Fit model with given features and labels\n",
    "        \n",
    "        Arguments:\n",
    "        X_train -- input training dataset,  shape = [n_samples, n_features]\n",
    "        Y_train -- labels of training data, shape = [n_samples]\n",
    "        \n",
    "        \"\"\"\n",
    "        # Get a list of prior probability of Y==ck\n",
    "        self.prior_prob = self.compute_prior_prob(Y_train)\n",
    "        # Get the num of input dimensions\n",
    "        dim_x = X_train.shape[1]\n",
    "        \n",
    "        # Define a lise of x_variety: the num of potential types in each dimension\n",
    "        self.x_variety = []\n",
    "        # Get the max value of potential types in all dimensions, and set it as dim of prob_matrix\n",
    "        for i in range(dim_x):\n",
    "            current_column = X_train[:,i]\n",
    "            self.x_variety.append(np.unique(current_column))\n",
    "        max_variety = np.max([len(x_i) for x_i in self.x_variety])\n",
    "        \n",
    "        # Define conditional probability of x under y: dict={'Y=ck': prob_matrix[n_dims, n_variety]}\n",
    "        self.con_probs = {}\n",
    "        for label in np.unique(Y_train):\n",
    "            prob_x_under_yi = X_train[np.where(Y_train==label)] \n",
    "            # Calculate prob matrix with the shape of [n_dims, n_variety]\n",
    "            prob_matrix = np.zeros([dim_x, max_variety]) \n",
    "            for i in range(dim_x):\n",
    "                for j in range(max_variety):\n",
    "                    prob = self.compute_conditional_prob(prob_x_under_yi,dim_x=i, class_x=j) \n",
    "                    prob_matrix[i,j] = prob\n",
    "            # Add current conditional probability into all types of Y\n",
    "            self.con_probs[label] = prob_matrix\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict the label of input query \n",
    "        \n",
    "        Argument:\n",
    "        x -- feature vector of input query\n",
    "        \n",
    "        Return:\n",
    "        rpediction -- the most likely result of Y\n",
    "        \n",
    "        \"\"\"       \n",
    "        # Get the posterior probabilities of each kind of Y\n",
    "        d = self.compute_posterior_prob(x)\n",
    "        # Find the label which has the maximum likelihood\n",
    "        prediction = max(d, key=d.get)\n",
    "        # Return the result of predicting\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    \n",
    "    def compute_prior_prob(self, data_list):\n",
    "        \"\"\"\n",
    "        Compute the prior probability of different type of Y==ck\n",
    "        \n",
    "        Argument:\n",
    "        data_list -- input data,  shape = [n_samples]\n",
    "        \n",
    "        Return:\n",
    "        d -- dict = {type of y: prior probability of corresponding y}\n",
    "        \n",
    "        \"\"\" \n",
    "        d = {}\n",
    "        num = len(data_list)\n",
    "        for n in data_list:\n",
    "            if n in d:\n",
    "                d[n] = d[n] + 1/num\n",
    "            else:\n",
    "                d[n] = 1/num\n",
    "                \n",
    "        return d\n",
    "    \n",
    "    \n",
    "    def compute_conditional_prob(self,x, dim_x, class_x):\n",
    "        \"\"\"\n",
    "        Compute the conditional probabilities of each P(Xj=xi|Y=ck)\n",
    "        \n",
    "        Arguments:\n",
    "        x -- input dataset with the shape of [n_samples, n_features]\n",
    "        dim_x -- the condition of j in P(Xj=xi|Y=ck)\n",
    "        class_x -- the condition of i in P(Xj=xi|Y=ck)\n",
    "        \n",
    "        Return:\n",
    "        con_prob -- the conditionl probability of P(Xj=xi|Y=ck)\n",
    "        \n",
    "        \"\"\" \n",
    "        # Extract the column which we want, and get its variety \n",
    "        column = x[:,dim_x]\n",
    "        variety = np.unique(column)\n",
    "        \n",
    "        # Calculate the conditional probability under given conditions\n",
    "        con_prob = 0\n",
    "        # Whether over the bounndary\n",
    "        if len(variety) <= class_x:\n",
    "            return con_prob\n",
    "        else:\n",
    "            for n in column:\n",
    "                if n==variety[class_x]:\n",
    "                    con_prob += 1/len(column)\n",
    "            return con_prob\n",
    "        \n",
    "        \n",
    "    def compute_posterior_prob(self, x):\n",
    "        \"\"\"\n",
    "        Compute the posterior probabilities of each P(Y=ck|X=x)\n",
    "        \n",
    "        Argument:\n",
    "        x -- feature vector of query point\n",
    "        \n",
    "        Return:\n",
    "        posterior_prob -- the posterior probability of P(Y=ck|X=x)\n",
    "        \n",
    "        \"\"\"     \n",
    "        # Define a dict for different types of Y=ck\n",
    "        posterior_prob = {}\n",
    "        \n",
    "        # Get posterior probability: P(Y=ck|X=x)\n",
    "        for key,value in self.con_probs.items():\n",
    "            prob_matrix = value\n",
    "            temp_prob = 1\n",
    "            for i in range(len(x)):\n",
    "                j = np.where(self.x_variety[i]==x[i])\n",
    "                temp_prob *= prob_matrix[i,j] \n",
    "            posterior_prob[key] = self.prior_prob[key] * temp_prob\n",
    "        \n",
    "        # Return all the potential posterior probabilities\n",
    "        return posterior_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P50 例 4.1*  \n",
    "  \n",
    "试由以下表格的训练数据学习一个朴素贝叶斯分类器并确定x=(2,S)<sup>(T)</sup>的类标记y. 表中X<sup>(1)</sup>, X<sup>(2)</sup>为特征, 取值的集合分别为A<sub>1</sub>={1,2,3}, A<sub>2</sub>={S,M,L}, Y为类标记, Y∈C={1,-1}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|     | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 |\n",
    "| :--  | --: |\n",
    "|**X<sup>(1)</sup>**| 1 | 1 | 1 | 1 | 1 | 2 | 2 | 2 | 2 | 2 | 3 | 3 | 3 | 3 | 3 |\n",
    "|**X<sup>(2)</sup>**| S | M | M | S | S | S | M | M | L | L | L | M | M | L | L | \n",
    "|**     Y     **| -1| -1| 1 | 1 | -1| -1| -1| 1 | 1 | 1 | 1 | 1 | 1 | 1 | -1| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate artificial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,'S'], [1,'M'], [1,'M'], [1,'S'], [1,'S'], [2,'S'], [2,'M'], [2,'M'], [2,'L'], [2,'L'], \n",
    "              [3,'L'], [3,'M'], [3,'M'], [3,'L'], [3,'L']])\n",
    "y = np.array([-1, -1, 1, 1, -1, -1, -1, 1 ,1 ,1 ,1 ,1 ,1 ,1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- creating and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NaiveBayes()\n",
    "model.fit(X_train=x, Y_train=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: class =  -1\n"
     ]
    }
   ],
   "source": [
    "query = np.array([2, 'S'])\n",
    "pred = model.predict(query)\n",
    "print('Prediction: class = ', pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
